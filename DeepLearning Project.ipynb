{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import glob\n",
    "import cv2 as cv\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from PIL import Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading DATA \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = r\"C:\\Users\\user\\Documents\\RAPID-master\\datasets\\training_data\\images\"\n",
    "test = r\"C:\\Users\\user\\Documents\\RAPID-master\\datasets\\test_data\\images\"\n",
    "\n",
    "trainlb = np.load(r'C:\\Users\\user\\Documents\\RAPID-master\\datasets\\training_data\\labels.npy')\n",
    "testlb = np.load(r'C:\\Users\\user\\Documents\\RAPID-master\\datasets\\test_data\\labels.npy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = []\n",
    "y_tr = []\n",
    "i = 0\n",
    "def create_training_data():\n",
    "        i = 0\n",
    "        for img in tqdm(os.listdir(train)):\n",
    "                img_array = cv.imread(os.path.join(train,img) ,cv.IMREAD_COLOR)  # convert to array\n",
    "                new_array = np.array(cv.resize(img_array, (224, 224))) # resize data\n",
    "                mean = np.mean(new_array, axis=(0, 1)) # mean for data centering\n",
    "                std = np.std(new_array, axis=(0, 1)) # standard deviation\n",
    "                normalized_image_array = (new_array - mean) / std # normalize the image\n",
    "                x_tr.append(normalized_image_array)\n",
    "                y_tr.append(trainlb[i])\n",
    "                i =i+1 \n",
    "create_training_data()\n",
    "\n",
    "print(len(x_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ts = []\n",
    "y_ts = []\n",
    "i = 0\n",
    "def create_training_data():\n",
    "        i = 0\n",
    "        for img in tqdm(os.listdir(test)):\n",
    "                img_array = cv.imread(os.path.join(test,img) ,cv.IMREAD_COLOR)  # convert to array\n",
    "                new_array = np.array(cv.resize(img_array, (224, 224)))  # resize data\n",
    "                mean = np.mean(new_array, axis=(0, 1)) # mean for data centering\n",
    "                std = np.std(new_array, axis=(0, 1)) # standard deviation\n",
    "                normalized_image_array = (new_array - mean) / std # normalize the image\n",
    "                x_ts.append(normalized_image_array) \n",
    "                y_ts.append(testlb[i])\n",
    "                i =i+1 \n",
    "create_training_data()\n",
    "\n",
    "print(len(x_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(x_tr), np.shape((y_tr)))\n",
    "print(np.shape(x_ts), np.shape((y_ts)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA VISUALISATION\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we took the vecctors and reshaped them into a 20x10 matrix and streteched them to 224x224 in order to simulate the areas with the lowest moisture dissapation rates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "for i in range(8):\n",
    "  \n",
    "  plt.subplot(4,4,i+1)\n",
    "  imageI = cv.resize((trainlb[i].reshape(20,10)),(224,224),  interpolation= cv.INTER_LINEAR)\n",
    "  plt.imshow(imageI, cmap= 'viridis')\n",
    "  plt.subplots_adjust(hspace=0.5)\n",
    "  plt.title(\"Image{}\".format(i))\n",
    "  plt.axis('on')\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we visualized a sample of the images  of the aerial view of the vinyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "\n",
    "for i in range(8):\n",
    "  \n",
    "  plt.subplot(4,4,i+1)\n",
    "  image= x_tr[i]\n",
    "  plt.imshow(image, cmap = 'viridis')\n",
    "  plt.subplots_adjust(hspace=0.5)\n",
    "  plt.title(\"Image{}\".format(i))\n",
    "  plt.axis('on')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = tf.stack(x_tr)  # convert to tensor\n",
    "y_tr = tf.stack(y_tr) # convert to tensor\n",
    "x_ts = tf.stack(x_ts) # convert to tensor\n",
    "y_ts = tf.stack(y_ts) # convert to tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our CNN is composed of 2 conculutional layers followed with a max pooling and a droupout layer and then we adapt the output to suit our task at hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "# Create the CNN model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(224, 224,3)))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(0.4))\n",
    "\n",
    "model.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(0.4))\n",
    "#Flattening \n",
    "model.add(layers.Flatten())\n",
    "#output \n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(200))  # Output layer without activation function\n",
    "#model summary \n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam',metrics=['mae'])\n",
    "\n",
    "Early_Stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "hist= model.fit(x_tr, y_tr, batch_size=batch_size , epochs=epochs, validation_data=(x_ts, y_ts),callbacks=[Early_Stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams.update({'font.size': 7})\n",
    "plt.plot(hist.history[\"loss\"],c='b',label=\"Ens. d'apprentissage\")\n",
    "plt.plot(hist.history[\"val_loss\"],c='r',label=\"Ens. de test\")\n",
    "plt.title(\"CNN with dropout MSE\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['mae'])\n",
    "plt.plot(hist.history['val_mae'])\n",
    "plt.title(\"CNN with dropout MAE\")\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(['Train mae', 'Validation mae'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Transfer learning**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionV3\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in order to tryout the partial fine tuning we freeze the first 100 layers of the InveptionV3 model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Load InceptionV3 model without the top (fully connected) layers\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers[:100]: # Freeze the first 100 layers\n",
    "    layer.trainable=False\n",
    "\n",
    "# Create a new model and add InceptionV3 as a base\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "\n",
    "# Add custom layers on top of InceptionV3 for our output\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(200))  # No activation for regression output\n",
    "\n",
    "#model.summary\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.01), loss='mean_squared_error',metrics=['mae'])\n",
    "\n",
    "# Early stopping\n",
    "Early_Stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    ")\n",
    "# Train the model\n",
    "histIncce =  model.fit(x_tr, y_tr, batch_size=10, epochs=50, validation_data=(x_ts, y_ts),callbacks=[Early_Stopping])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the MSE curve for InceptionV3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams.update({'font.size': 7})\n",
    "plt.plot(histIncce.history[\"loss\"],c='b',label=\"Ens. d'apprentissage\")\n",
    "plt.plot(histIncce.history[\"val_loss\"],c='r',label=\"Ens. de test\")\n",
    "plt.title('MSE results for InceptionV3 without freezed layers')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.ylim([0, 0.5])\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the MAE curve for InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(histIncce.history['mae'])\n",
    "plt.plot(histIncce.history['val_mae'])\n",
    "plt.title('MAE results for InceptionV3 without freezed layers')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0, 0.5])\n",
    "plt.legend(['Train mae loss', 'Validation mae loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNET50"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in order to tryout the partial fine tuning we freeze the first 100 layers of the ResNET50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "#from keras.applications import ResNet50\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Load ResNet50 model without the top (fully connected) layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers[:100]: # Freeze the first 100 layers\n",
    "    layer.trainable=False\n",
    "\n",
    "# Create a new model and add ResNet50 as a base\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "\n",
    "# Add custom layers on top of ResNet50 for our output\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(200))  \n",
    "\n",
    "model.summary()\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error',metrics=['mae'])\n",
    "\n",
    "# Early stopping    \n",
    "Early_Stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "histRN50 =  model.fit(x_tr, y_tr, batch_size=10, epochs=50 ,validation_data=(x_ts, y_ts),callbacks=[Early_Stopping])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the MSE curve for InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams.update({'font.size': 7})\n",
    "plt.plot(histRN50.history[\"loss\"],c='b',label=\"Ens. d'apprentissage\")\n",
    "plt.plot(histRN50.history[\"val_loss\"],c='r',label=\"Ens. de test\")\n",
    "plt.title('MSE results for ResNET50 without freezed layers')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.ylim([0, 40])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the MAE curve for InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(histRN50.history['mae'])\n",
    "plt.plot(histRN50.history['val_mae'])\n",
    "plt.title('MAE results for ResNET50 without freezed layers')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0, 40])\n",
    "plt.legend(['Train mae', 'Validation mae'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in order to tryout the partial fine tuning we freeze the first 15 layers of the VGG19 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Load VGG19 model without the top (fully connected layers)\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers[:15]: # Freeze the first 15 layers\n",
    "    layer.trainable=False\n",
    "\n",
    "# Create a new model and add VGG19 as a base\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "\n",
    "# Add custom layers on top of VGG19\n",
    "model.add(Flatten())\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(200))  # No activation for regression output\n",
    "\n",
    "\n",
    "model.summary()\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error',metrics=['mae'])\n",
    "\n",
    "# Early stopping\n",
    "Early_Stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    ")\n",
    "\n",
    "\n",
    "# Train the model\n",
    "histVGG =  model.fit(x_tr, y_tr, batch_size=10, epochs=50, validation_data=(x_ts, y_ts),callbacks=[Early_Stopping])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the MSE curve for VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 7})\n",
    "plt.plot(histVGG.history[\"loss\"],c='b',label=\"Ens. d'apprentissage\")\n",
    "plt.plot(histVGG.history[\"val_loss\"],c='r',label=\"Ens. de test\")\n",
    "plt.title('MSE results for VGG19 without freezed layers')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.ylim([0, 0.5])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the MAE curve for VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(histVGG.history['mae'])\n",
    "plt.plot(histVGG.history['val_mae'])\n",
    "plt.title('MAE results for VGG19 without freezed layers')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0, 0.5])\n",
    "plt.legend(['Train mae', 'Validation mae'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in order to tryout the partial fine tuning we freeze the first 10 layers of the Xception model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.xception import Xception\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Load Xception model without the top (fully connected) layers\n",
    "base_model = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers[:10]: # Freeze the first 10 layers\n",
    "    layer.trainable=False\n",
    "\n",
    "# Create a new model and add Xception as a base\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "\n",
    "# Add custom layers on top of Xception for our output\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(200))  \n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.01), loss='mean_squared_error',metrics=['mae'])\n",
    "#Early Stopping  \n",
    "Early_Stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "histXce =  model.fit(x_tr, y_tr, batch_size=10, epochs=50, validation_data=(x_ts, y_ts),callbacks=[Early_Stopping])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the MSE curve for Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 7})\n",
    "plt.plot(histXce.history[\"loss\"],c='b',label=\"Ens. d'apprentissage\")\n",
    "plt.plot(histXce.history[\"val_loss\"],c='r',label=\"Ens. de test\")\n",
    "plt.title('MSE results for Xception without freezed layers')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.ylim([0, 0.5])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the MAE curve for Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(histXce.history['mae'])\n",
    "plt.plot(histXce.history['val_mae'])\n",
    "plt.title('MAE results for Xception without  freezed layers')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0, 0.5])\n",
    "plt.legend(['Train mae', 'Validation mae'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
